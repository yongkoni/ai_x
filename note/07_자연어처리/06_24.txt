Attention으로 번역기 만들기

어텐션 함수는 Q(Query), K(Keys), V(Values)를 매개변수로 사용
	Q(Query)는 특정 시점에서의 디코더 셀의 은닉 상태
	K(Key)는 모든 시점에서의 인코더 셀의 Q를 반영하기 전 은닉 상태
	V(Value)는 모든 시점에서의 인코더 셀의 Q 반영 후 은닉 상태

어텐션 함수는 주어진 질의(Query)에 대해서 모든 키(Key)와 각각의 유사도를 계산
계산된 유사도를 키와 매핑되어 있는 각각의 값(Value)에 반영
유사도가 반영된 값(Value)을 모두 어텐션 값(Attention Value)으로 반환


Transformer로 영화평감성 분석
	인코더 층만으로 구현(입력 : 자연어, 출력 : 긍정/부정)

입력 처리 : 문장을 단어 단위로 쪼개어 각 단어를 수치로 변환(임베딩)
어텐션 메커니즘 (Attention Mechanism)
인코더 : 입력 문장을 받아 어텐션을 통해 의미 있는 벡터로 변환
디코더 : 인코더에서 얻은 벡터를 받아 새로운 문장을 생성하거나, 번역 작업 등을 수행
병렬 처리 : 트랜스포머는 RNN이나 LSTM과 달리 모든 단어를 한 번에 처리할 수 있어 학습이 빠름




