인공지능학습 : 비지도학습 vs 지도학습(DNN)

- DNN
- 스케일조정(정규화, 표준화)하는 목적? : 계산의 안정성 향상

- 모델구현
model = Sequential() - 순차적인 레이어 모델 생성 / model = Model() - 병렬 레이어 모델 생성
- 이진분류 출력층 model.add(Dense(1, activation = 'sigmoid'))
- 다중분류 출력층 model.add(Dense(n, activation = 'softmax'))

- 학습과정 설정
손실함수(loss) = (이중분류, 다중분류 categorical_crossentropy)
옵티마이저(optimizer) = (Adam)
평가지표(metrics) = (accuracy)
		예측 0	예측 1 
	실제 0	  TN	  FP
	실제 1	  FN	  TP

	※ accuracy(정확도) = (TN + TP) / (TN + FN + TP + FP)
	※ precision(정밀도) = TP / (FP - TP) - 예측값 기준
	※ recall(재현율) = TP / (FP + TP) - 실제값 기준

- accuracy를 늘리기 위한 방법 : 데이터 확보, 레이어, units, 활성화 함수, epoch, optimizer

- 과적합 방지를 위한 방법 : 데이터 확보, 증강, Dropout, 활성화 relu

- 모델저장 : 딥러닝에서의 모델 저장 → *.h5

- 자연어처리 konlpy (nouns : 명사만 추출, pos : 한문장을 단어 단위로 나눠 품사 태깅)

- RNN/LSTM : 시계열데이터 예측, 자연어 생성, 작곡/편곡 

